{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [8.0*2, 6.0*2]\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "mpl.rcParams['savefig.dpi'] = 100\n",
    "\n",
    "mpl.rcParams['font.size'] = 30\n",
    "mpl.rcParams['axes.labelsize'] = 30\n",
    "mpl.rcParams['ytick.labelsize'] = 30\n",
    "mpl.rcParams['xtick.labelsize'] = 30\n",
    "mpl.rcParams['legend.fontsize'] = 'large'\n",
    "mpl.rcParams['figure.titlesize'] = 'medium'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "On fait des plots sur les runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.workflow import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.higgs_uci import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "print('Loading data ...')\n",
    "data, _ = load_data()\n",
    "print('Done !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRI_tau_pt</th>\n",
       "      <th>PRI_tau_eta</th>\n",
       "      <th>PRI_tau_phi</th>\n",
       "      <th>PRI_lep_pt</th>\n",
       "      <th>PRI_lep_eta</th>\n",
       "      <th>PRI_lep_phi</th>\n",
       "      <th>PRI_met</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>Label</th>\n",
       "      <th>Weight</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_ratio_lep_tau</th>\n",
       "      <th>DER_met_phi_centrality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29.284</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>1.256</td>\n",
       "      <td>23.948</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-2.130</td>\n",
       "      <td>22.594</td>\n",
       "      <td>-0.278</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>37.186</td>\n",
       "      <td>52.592</td>\n",
       "      <td>18.160</td>\n",
       "      <td>2.898</td>\n",
       "      <td>0.818</td>\n",
       "      <td>-1.414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.197</td>\n",
       "      <td>-2.032</td>\n",
       "      <td>-2.739</td>\n",
       "      <td>21.636</td>\n",
       "      <td>-2.303</td>\n",
       "      <td>0.343</td>\n",
       "      <td>32.296</td>\n",
       "      <td>0.031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>8.212</td>\n",
       "      <td>54.889</td>\n",
       "      <td>21.805</td>\n",
       "      <td>3.094</td>\n",
       "      <td>0.633</td>\n",
       "      <td>1.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.348</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-2.277</td>\n",
       "      <td>21.792</td>\n",
       "      <td>-2.040</td>\n",
       "      <td>0.544</td>\n",
       "      <td>57.737</td>\n",
       "      <td>0.405</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>4.929</td>\n",
       "      <td>65.989</td>\n",
       "      <td>60.528</td>\n",
       "      <td>3.453</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.196</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.171</td>\n",
       "      <td>25.078</td>\n",
       "      <td>1.035</td>\n",
       "      <td>-3.020</td>\n",
       "      <td>37.849</td>\n",
       "      <td>-3.114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2.897</td>\n",
       "      <td>61.632</td>\n",
       "      <td>28.113</td>\n",
       "      <td>3.139</td>\n",
       "      <td>0.713</td>\n",
       "      <td>1.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.387</td>\n",
       "      <td>1.301</td>\n",
       "      <td>-1.953</td>\n",
       "      <td>25.875</td>\n",
       "      <td>2.194</td>\n",
       "      <td>1.165</td>\n",
       "      <td>5.599</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.005</td>\n",
       "      <td>16.920</td>\n",
       "      <td>69.428</td>\n",
       "      <td>14.024</td>\n",
       "      <td>3.244</td>\n",
       "      <td>0.674</td>\n",
       "      <td>1.414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PRI_tau_pt  PRI_tau_eta  PRI_tau_phi  PRI_lep_pt  PRI_lep_eta  PRI_lep_phi  \\\n",
       "0      29.284       -0.563        1.256      23.948       -0.600       -2.130   \n",
       "1      34.197       -2.032       -2.739      21.636       -2.303        0.343   \n",
       "2      21.348       -0.050       -2.277      21.792       -2.040        0.544   \n",
       "3      35.196        0.490        0.171      25.078        1.035       -3.020   \n",
       "4      38.387        1.301       -1.953      25.875        2.194        1.165   \n",
       "\n",
       "   PRI_met  PRI_met_phi  Label  Weight  DER_mass_transverse_met_lep  \\\n",
       "0   22.594       -0.278    1.0   0.005                       37.186   \n",
       "1   32.296        0.031    1.0   0.005                        8.212   \n",
       "2   57.737        0.405    1.0   0.005                        4.929   \n",
       "3   37.849       -3.114    1.0   0.005                        2.897   \n",
       "4    5.599       -0.393    1.0   0.005                       16.920   \n",
       "\n",
       "   DER_mass_vis  DER_pt_h  DER_deltar_tau_lep  DER_pt_ratio_lep_tau  \\\n",
       "0        52.592    18.160               2.898                 0.818   \n",
       "1        54.889    21.805               3.094                 0.633   \n",
       "2        65.989    60.528               3.453                 1.021   \n",
       "3        61.632    28.113               3.139                 0.713   \n",
       "4        69.428    14.024               3.244                 0.674   \n",
       "\n",
       "   DER_met_phi_centrality  \n",
       "0                  -1.414  \n",
       "1                   1.409  \n",
       "2                   1.253  \n",
       "3                   1.385  \n",
       "4                   1.414  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.higgs_uci import get_save_directory\n",
    "from problem.higgs_uci import skew\n",
    "from problem.higgs_uci import tangent\n",
    "from problem.higgs_uci import get_cv_iter\n",
    "\n",
    "# from main import get_data_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models(model_class, *args, **kwargs):\n",
    "    models = []\n",
    "    cv_iter = get_cv_iter(data, data['Label'])\n",
    "    n_cv = len(cv_iter)\n",
    "    pprint('Loading', n_cv, model_class.__name__)\n",
    "    for i in range(n_cv):\n",
    "        model = model_class(*args, **kwargs)\n",
    "        save_directory = get_save_directory()\n",
    "        model_name = '{}-{}'.format(model.get_name(), i)\n",
    "        path = os.path.join(save_directory, model_name)\n",
    "        model.load(path)\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.higgsuci import NeuralNetModel\n",
    "from models.higgsuci import AugmentedNeuralNetModel\n",
    "from models.higgsuci import TangentPropModel\n",
    "from models.higgsuci import AugmentedTangentPropModel\n",
    "from models.higgsuci import PivotModel\n",
    "from models.higgsuci import CascadeNeuralNetModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem.higgs_uci import test_submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import basic_metrics_xp\n",
    "from experiment import merge_decision_xp\n",
    "from experiment import complete_metrics_xp\n",
    "from experiment import systematic_xp\n",
    "from experiment import reduce_mean_xp\n",
    "from experiment import reduce_std_xp\n",
    "\n",
    "def get_syst_xp(xp, training_TES=1.0, n_bin=5000):\n",
    "    xp = basic_metrics_xp(xp, n_bin=n_bin)\n",
    "    xp = merge_decision_xp(xp)\n",
    "    xp = complete_metrics_xp(xp)\n",
    "    syst_xp = systematic_xp(xp, training_TES)\n",
    "    return syst_xp\n",
    "\n",
    "def get_mean_std_xp(xp, training_TES=1.0, n_bin=5000):\n",
    "    syst_xp = get_syst_xp(xp, training_TES, n_bin=n_bin)\n",
    "    xp_mean = reduce_mean_xp(syst_xp)\n",
    "    xp_std = reduce_std_xp(syst_xp)\n",
    "    return xp_mean, xp_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 1.003)\n"
     ]
    }
   ],
   "source": [
    "# z_list = list(range(-50, 51, 10)) + list(range(-5, 6, 1))\n",
    "# z_list = sorted(z_list)\n",
    "# z_list = np.linspace(-10, 10, num=20)\n",
    "# z_list = (1.0, 1.005, 1.01, 1.03)\n",
    "# z_list = (1.0, 1.005, 1.003, 1.01, 0.995, 0.997, 0.99)\n",
    "# z_list = (1.0, 1.003, 1.005, 0.997, 0.995)\n",
    "z_list = (1.0, 1.003,)\n",
    "\n",
    "print( z_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-16 14:07:50 Loading 12 CascadeNeuralNetModel\n",
      "2018-02-16 14:08:12 testing model 1/12\n",
      "2018-02-16 14:08:42 testing model 2/12\n",
      "2018-02-16 14:09:10 testing model 3/12\n",
      "2018-02-16 14:09:40 testing model 4/12\n",
      "2018-02-16 14:10:08 testing model 5/12\n",
      "2018-02-16 14:10:38 testing model 6/12\n",
      "2018-02-16 14:11:06 testing model 7/12\n",
      "2018-02-16 14:11:35 testing model 8/12\n",
      "2018-02-16 14:12:03 testing model 9/12\n",
      "2018-02-16 14:12:32 testing model 10/12\n",
      "2018-02-16 14:13:01 testing model 11/12\n",
      "2018-02-16 14:13:30 testing model 12/12\n",
      "2018-02-16 14:13:47 Done.\n"
     ]
    }
   ],
   "source": [
    "NNC_95_models = load_models(CascadeNeuralNetModel, n_steps=10000, batch_size=1024, \n",
    "                            fraction_signal_to_keep=0.95, cuda=True)\n",
    "NNC_95_xp = test_submission(data, NNC_95_models, all_sysTES=z_list)\n",
    "NNC_95_mean, NNC_95_std = get_mean_std_xp( NNC_95_xp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-16 14:14:02 Loading 12 CascadeNeuralNetModel\n",
      "2018-02-16 14:14:18 testing model 1/12\n",
      "2018-02-16 14:14:46 testing model 2/12\n",
      "2018-02-16 14:15:14 testing model 3/12\n",
      "2018-02-16 14:15:41 testing model 4/12\n",
      "2018-02-16 14:16:08 testing model 5/12\n",
      "2018-02-16 14:16:35 testing model 6/12\n",
      "2018-02-16 14:17:03 testing model 7/12\n",
      "2018-02-16 14:17:32 testing model 8/12\n",
      "2018-02-16 14:18:00 testing model 9/12\n",
      "2018-02-16 14:18:35 testing model 10/12\n",
      "2018-02-16 14:19:07 testing model 11/12\n",
      "2018-02-16 14:19:58 testing model 12/12\n",
      "2018-02-16 14:20:14 Done.\n"
     ]
    }
   ],
   "source": [
    "NNC_75_models = load_models(CascadeNeuralNetModel, n_steps=10000, batch_size=1024, \n",
    "                            fraction_signal_to_keep=0.75, cuda=True)\n",
    "NNC_75_xp = test_submission(data, NNC_75_models, all_sysTES=z_list)\n",
    "NNC_75_mean, NNC_75_std = get_mean_std_xp( NNC_75_xp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-16 14:20:28 Loading 12 CascadeNeuralNetModel\n",
      "2018-02-16 14:20:50 testing model 1/12\n",
      "2018-02-16 14:21:53 testing model 2/12\n",
      "2018-02-16 14:22:52 testing model 3/12\n",
      "2018-02-16 14:23:36 testing model 4/12\n",
      "2018-02-16 14:24:33 testing model 5/12\n",
      "2018-02-16 14:25:25 testing model 6/12\n",
      "2018-02-16 14:26:22 testing model 7/12\n",
      "2018-02-16 14:27:23 testing model 8/12\n",
      "2018-02-16 14:28:12 testing model 9/12\n",
      "2018-02-16 14:29:16 testing model 10/12\n",
      "2018-02-16 14:30:24 testing model 11/12\n",
      "2018-02-16 14:31:37 testing model 12/12\n",
      "2018-02-16 14:32:04 Done.\n"
     ]
    }
   ],
   "source": [
    "NNC_50_models = load_models(CascadeNeuralNetModel, n_steps=10000, batch_size=1024, \n",
    "                            fraction_signal_to_keep=0.50, cuda=True)\n",
    "NNC_50_xp = test_submission(data, NNC_50_models, all_sysTES=z_list)\n",
    "NNC_50_mean, NNC_50_std = get_mean_std_xp( NNC_50_xp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-16 14:32:16 Loading 12 NeuralNetModel\n",
      "2018-02-16 14:32:46 testing model 1/12\n",
      "2018-02-16 14:33:42 testing model 2/12\n",
      "2018-02-16 14:34:44 testing model 3/12\n",
      "2018-02-16 14:35:31 testing model 4/12\n",
      "2018-02-16 14:36:31 testing model 5/12\n",
      "2018-02-16 14:37:29 testing model 6/12\n",
      "2018-02-16 14:38:35 testing model 7/12\n",
      "2018-02-16 14:39:40 testing model 8/12\n"
     ]
    }
   ],
   "source": [
    "NN_models = load_models(NeuralNetModel, n_steps=10000, batch_size=1024, cuda=True)\n",
    "NN_xp = test_submission(data, NN_models, all_sysTES=z_list)\n",
    "NN_mean, NN_std = get_mean_std_xp( NN_xp )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot\n",
    "\n",
    "\n",
    "- What about confusion matrices ???\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savitzky_golay(y, window_size, order, deriv=0, rate=1):\n",
    "    r\"\"\"Smooth (and optionally differentiate) data with a Savitzky-Golay filter.\n",
    "    The Savitzky-Golay filter removes high frequency noise from data.\n",
    "    It has the advantage of preserving the original shape and\n",
    "    features of the signal better than other types of filtering\n",
    "    approaches, such as moving averages techniques.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : array_like, shape (N,)\n",
    "        the values of the time history of the signal.\n",
    "    window_size : int\n",
    "        the length of the window. Must be an odd integer number.\n",
    "    order : int\n",
    "        the order of the polynomial used in the filtering.\n",
    "        Must be less then `window_size` - 1.\n",
    "    deriv: int\n",
    "        the order of the derivative to compute (default = 0 means only smoothing)\n",
    "    Returns\n",
    "    -------\n",
    "    ys : ndarray, shape (N)\n",
    "        the smoothed signal (or it's n-th derivative).\n",
    "    Notes\n",
    "    -----\n",
    "    The Savitzky-Golay is a type of low-pass filter, particularly\n",
    "    suited for smoothing noisy data. The main idea behind this\n",
    "    approach is to make for each point a least-square fit with a\n",
    "    polynomial of high order over a odd-sized window centered at\n",
    "    the point.\n",
    "    Examples\n",
    "    --------\n",
    "    t = np.linspace(-4, 4, 500)\n",
    "    y = np.exp( -t**2 ) + np.random.normal(0, 0.05, t.shape)\n",
    "    ysg = savitzky_golay(y, window_size=31, order=4)\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(t, y, label='Noisy signal')\n",
    "    plt.plot(t, np.exp(-t**2), 'k', lw=1.5, label='Original signal')\n",
    "    plt.plot(t, ysg, 'r', label='Filtered signal')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] A. Savitzky, M. J. E. Golay, Smoothing and Differentiation of\n",
    "       Data by Simplified Least Squares Procedures. Analytical\n",
    "       Chemistry, 1964, 36 (8), pp 1627-1639.\n",
    "    .. [2] Numerical Recipes 3rd Edition: The Art of Scientific Computing\n",
    "       W.H. Press, S.A. Teukolsky, W.T. Vetterling, B.P. Flannery\n",
    "       Cambridge University Press ISBN-13: 9780521880688\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from math import factorial\n",
    "    \n",
    "    try:\n",
    "        window_size = np.abs(np.int(window_size))\n",
    "        order = np.abs(np.int(order))\n",
    "    except ValueError as msg:\n",
    "        raise ValueError(\"window_size and order have to be of type int\")\n",
    "    if window_size % 2 != 1 or window_size < 1:\n",
    "        raise TypeError(\"window_size size must be a positive odd number\")\n",
    "    if window_size < order + 2:\n",
    "        raise TypeError(\"window_size is too small for the polynomials order\")\n",
    "    order_range = range(order+1)\n",
    "    half_window = (window_size -1) // 2\n",
    "    # precompute coefficients\n",
    "    b = np.mat([[k**i for i in order_range] for k in range(-half_window, half_window+1)])\n",
    "    m = np.linalg.pinv(b).A[deriv] * rate**deriv * factorial(deriv)\n",
    "    # pad the signal at the extremes with\n",
    "    # values taken from the signal itself\n",
    "    firstvals = y[0] - np.abs( y[1:half_window+1][::-1] - y[0] )\n",
    "    lastvals = y[-1] + np.abs(y[-half_window-1:-1][::-1] - y[-1])\n",
    "    y = np.concatenate((firstvals, y, lastvals))\n",
    "    return np.convolve( m[::-1], y, mode='valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tes_to_str(TES):\n",
    "    return '{:+1.1f}%'.format( (TES-1)*100 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special graphics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOSEN_TES = 1.003\n",
    "\n",
    "means = [NN_mean, NNC_95_mean, NNC_75_mean, NNC_50_mean]\n",
    "stds = [NN_std, NNC_95_std, NNC_75_std, NNC_50_std]\n",
    "names = ['NN', 'NNC-95', 'NNC-75', 'NNC-50']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 0.5\n",
    "STOP = 0.99\n",
    "# CHOSEN_TES = 1.01\n",
    "\n",
    "xp_mean = NN_mean\n",
    "xp_std = NN_std\n",
    "\n",
    "rank = pd.Series(np.linspace(0, 1, num=xp_mean[CHOSEN_TES]['decision'].shape[0]))\n",
    "index = rank.loc[ (rank > START) & (rank < STOP)].index\n",
    "xx = rank[index] * 100\n",
    "\n",
    "mean = xp_mean[CHOSEN_TES]['error_stat'][index]\n",
    "std = xp_std[CHOSEN_TES]['error_stat'][index]\n",
    "\n",
    "# Smoothing\n",
    "mean = savitzky_golay(mean.values, 1001, 3)\n",
    "std = savitzky_golay(std.values, 1001, 3)\n",
    "\n",
    "plt.plot(xx, mean, label='$\\sigma_0$')\n",
    "plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "\n",
    "\n",
    "mean = xp_mean[CHOSEN_TES]['sigma_mu'][index]\n",
    "std = xp_std[CHOSEN_TES]['sigma_mu'][index]\n",
    "\n",
    "# Smoothing\n",
    "mean = savitzky_golay(mean.values, 1001, 3)\n",
    "std = savitzky_golay(std.values, 1001, 3)\n",
    "\n",
    "plt.plot(xx, mean, label='$\\sigma_\\mu/\\mu$')\n",
    "plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "\n",
    "plt.ylim((0, 5))\n",
    "plt.xlim((50, 100))\n",
    "plt.plot([50, 86, 86], [1.40, 1.40, 0], 'r--', label='stat threshold')\n",
    "plt.plot([50, 86, 86], [0.55, 0.55, 0], 'b--', label='stat threshold')\n",
    "plt.plot([50, 97.3, 97.3], [0.83, 0.83, 0], 'g--', label='combined threshold')\n",
    "plt.xticks([50, 60, 70, 80, 90] + [86] + [97.3])\n",
    "plt.yticks(list(plt.yticks()[0]) + [0.28, 0.53, 1.80])\n",
    "\n",
    "\n",
    "plt.title('Neural network errors (TES = {})'.format(tes_to_str(CHOSEN_TES)))\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('% rejected event')\n",
    "plt.ylabel('errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigma mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 0.90\n",
    "STOP = 0.9975\n",
    "\n",
    "for xp_mean, xp_std, name in zip(means, stds, names):\n",
    "\n",
    "    rank = pd.Series(np.linspace(0, 1, num=xp_mean[CHOSEN_TES]['decision'].shape[0]))\n",
    "    index = rank.loc[ (rank > START) & (rank < STOP)].index\n",
    "    xx = rank[index] * 100\n",
    "\n",
    "    mean = xp_mean[CHOSEN_TES]['sigma_mu'][index]\n",
    "    std = xp_std[CHOSEN_TES]['sigma_mu'][index]\n",
    "    \n",
    "    # Smoothing\n",
    "    mean = savitzky_golay(mean.values, 1001, 3)\n",
    "    std = savitzky_golay(std.values, 1001, 3)\n",
    "    \n",
    "    plt.plot(xx, mean, label=name)\n",
    "#     plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "    plt.title('combined error RETRO-CHECK (TES = {})'.format(tes_to_str(CHOSEN_TES)), fontsize=30)\n",
    "    \n",
    "# plt.ylim(0, 10)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.xlabel('% rejected event', fontsize=30)\n",
    "plt.ylabel('$\\sigma_\\mu/\\mu$', fontsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 3000\n",
    "STOP = 100\n",
    "\n",
    "for xp_mean, xp_std, name in zip(means, stds, names):\n",
    "    \n",
    "\n",
    "    xx = xp_mean[CHOSEN_TES]['TP'] + xp_mean[CHOSEN_TES]['FP']\n",
    "    index = xx.loc[ (xx < START) & (xx > STOP)].index\n",
    "    #xx = (1 - xx / xx[0]) * 100  # Percentage\n",
    "    xx = xx[index]\n",
    "\n",
    "    mean = xp_mean[CHOSEN_TES]['sigma_mu'][index]\n",
    "    std = xp_std[CHOSEN_TES]['sigma_mu'][index]\n",
    "    \n",
    "    # Smoothing\n",
    "    mean = savitzky_golay(mean.values, 201, 3)\n",
    "    std = savitzky_golay(std.values, 201, 3)\n",
    "    \n",
    "    plt.plot(xx, mean, label=name)\n",
    "#     plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "    plt.title('combined error (TES = {})'.format(tes_to_str(CHOSEN_TES)))\n",
    "    \n",
    "# plt.ylim(0, 10)\n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()\n",
    "plt.xlabel('# event kept')\n",
    "plt.ylabel('$\\sigma_\\mu/\\mu$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat error"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "xp_mean[CHOSEN_TES]['error_stat'][index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 3000\n",
    "STOP = 40\n",
    "\n",
    "for xp_mean, xp_std, name in zip(means, stds, names):\n",
    "    \n",
    "    xx = xp_mean[CHOSEN_TES]['TP'] + xp_mean[CHOSEN_TES]['FP']\n",
    "    index = xx.loc[ (xx < START) & (xx > STOP)].index\n",
    "    #xx = (1 - xx / xx[0]) * 100  # Percentage\n",
    "    xx = xx[index]\n",
    "\n",
    "    mean = xp_mean[CHOSEN_TES]['error_stat'][index]\n",
    "    std = xp_std[CHOSEN_TES]['error_stat'][index]\n",
    "    \n",
    "    # Smoothing\n",
    "#     mean = savitzky_golay(mean.values, 1001, 3)\n",
    "#     std = savitzky_golay(std.values, 1001, 3)\n",
    "    \n",
    "    plt.plot(xx, mean, label=name)\n",
    "#     plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "    plt.title('stat error (TES = {})'.format(tes_to_str(CHOSEN_TES)))\n",
    "    \n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()\n",
    "plt.xlabel('# event kept')\n",
    "plt.ylabel('error stat')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syst error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = 3000\n",
    "STOP = 40\n",
    "\n",
    "for xp_mean, xp_std, name in zip(means, stds, names):\n",
    "\n",
    "    xx = xp_mean[CHOSEN_TES]['TP'] + xp_mean[CHOSEN_TES]['FP']\n",
    "    index = xx.loc[ (xx < START) & (xx > STOP)].index\n",
    "    #xx = (1 - xx / xx[0]) * 100  # Percentage\n",
    "    xx = xx[index]\n",
    "\n",
    "    mean = xp_mean[CHOSEN_TES]['error_syst'][index]\n",
    "    std = xp_std[CHOSEN_TES]['error_syst'][index]\n",
    "    \n",
    "    # Smoothing\n",
    "    mean = savitzky_golay(mean.values, 201, 3)\n",
    "    std = savitzky_golay(std.values, 201, 3)\n",
    "    \n",
    "    plt.plot(xx, mean, label=name)\n",
    "#     plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "    plt.title('syst error (TES = {})'.format(tes_to_str(CHOSEN_TES)))\n",
    "    \n",
    "plt.gca().invert_xaxis()\n",
    "plt.legend()\n",
    "plt.xlabel('# event kept')\n",
    "plt.ylabel('error syst')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "START = 0.\n",
    "STOP = 0.999\n",
    "\n",
    "for xp_mean, xp_std, name in zip(means, stds, names):\n",
    "\n",
    "    rank = pd.Series(np.linspace(0, 1, num=xp_mean[CHOSEN_TES]['decision'].shape[0]))\n",
    "    index = rank.loc[ (rank > START) & (rank < STOP)].index\n",
    "    xx = rank[index] * 100\n",
    "\n",
    "    mean = xp_mean[CHOSEN_TES]['TP'][index]\n",
    "    std = xp_std[CHOSEN_TES]['TP'][index]\n",
    "    \n",
    "    # Smoothing\n",
    "#     mean = savitzky_golay(mean.values, 201, 3)\n",
    "#     std = savitzky_golay(std.values, 201, 3)\n",
    "    \n",
    "    plt.plot(xx, mean, label=name)\n",
    "    plt.fill_between(xx, mean+std, mean-std, alpha=0.5)\n",
    "    plt.title('S (TES = {})'.format(tes_to_str(CHOSEN_TES)))\n",
    "    \n",
    "plt.legend()\n",
    "plt.xlabel('% rejected event')\n",
    "plt.ylabel('s_0')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "plt.plot(NN_models[i].loss_hook.losses[::50], label='NN')\n",
    "plt.plot(NNC_95_models[i].model_0.loss_hook.losses[::50], label='NNC_95-0')\n",
    "plt.plot(NNC_95_models[i].model_1.loss_hook.losses[::50], label='NNC_95-1')\n",
    "plt.plot(NNC_75_models[i].model_0.loss_hook.losses[::50], label='NNC_75-0')\n",
    "plt.plot(NNC_75_models[i].model_1.loss_hook.losses[::50], label='NNC_75-1')\n",
    "plt.plot(NNC_50_models[i].model_0.loss_hook.losses[::50], label='NNC_50-0')\n",
    "plt.plot(NNC_50_models[i].model_1.loss_hook.losses[::50], label='NNC_50-1')\n",
    "\n",
    "plt.title('Cross entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in NNC_95_models:\n",
    "    print('Threshold filter 95 :', m.filter_0.score_threshold_)\n",
    "\n",
    "for m in NNC_75_models:\n",
    "    print('Threshold filter 75 :', m.filter_0.score_threshold_)\n",
    "\n",
    "for m in NNC_50_models:\n",
    "    print('Threshold filter 50 :', m.filter_0.score_threshold_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "# class RANDOM(BaseEstimator, ClassifierMixin):\n",
    "#     def __init__(self, n_class=2):\n",
    "#         super().__init__()\n",
    "#         self.n_class = n_class\n",
    "\n",
    "#     def fit(self, X, y):\n",
    "#         self.n_class = len(np.unique(y))\n",
    "#         return self\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return np.random.randint(0, self.n_class+1, size=X.shape[0])\n",
    "\n",
    "#     def predict_proba(self, X):\n",
    "#         proba = np.random.uniform(0, 1, size=(X.shape[0], self.n_class))\n",
    "#         proba = proba / np.sum(proba, axis=1).reshape(-1, 1)\n",
    "#         return proba\n",
    "\n",
    "#     def save(self, path):\n",
    "#         pass\n",
    "\n",
    "#     def load(self, path):\n",
    "#         pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAND_models = [RANDOM() for i in range(12)]\n",
    "# RAND_xp = test_submission(data, RAND_models, all_sysTES=z_list)\n",
    "# RAND_mean, RAND_std = get_mean_std_xp( RAND_xp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
